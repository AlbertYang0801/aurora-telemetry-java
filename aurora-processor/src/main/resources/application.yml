spring:
  application:
    name: aurora-processor

  kafka:
    bootstrap-servers: 192.168.102.154:9092
    # kafka认证开关
    auth-switch: false
    config:
      # hostname校验改成空
      ssl:
        enable: true
        endpoint:
          identification:
            algorithm: ""
        # 建议设置为绝对路径
        truststore-location: monitor-common/ssl/xxx.jks
      # 接入协议，目前支持使用SASL_SSL协议接入
      security:
        protocol: SASL_SSL
      sasl:
        #PLAIN, SCRAM-SHA-256
        mechanism: PLAIN
        # 设置SASL账号密码，从控制台获取
        username: xxx
        password: xxx
        # 根证书store的密码，保持不变
        truststore_password: KafkaOnsClient

    consumer:
      # 如果为true，则为自动提交，消费者的偏移量将在后台定期提交(Kafka策略提交)，若为false，则为手动提交（spring策略提交）。
      enable-auto-commit: true
      # 消费者偏移自动提交给Kafka的频率 （以毫秒为单位），默认值为5000
      auto-commit-interval: 5000
      # 每次poll的最大数量, 注意该值不要改得太大，如果poll太多数据，而不能在下次poll之前消费完，则会触发一次负载均衡，产生卡顿
      max-poll-records: 1000
      # 设置单次拉取的量，走公网访问时，该参数会有较大影响
      max-partition-fetch-bytes: 32000
      fetch-max-bytes: 32000
      # 两次poll之间的最大允许间隔, 可更加实际拉去数据和客户的版本等设置此值，默认30s
      session-timeout: 30000


# 自定义kafka配置
kafka:
  custom:
    consumers:
      # 事件消费者
      - name: event-consumer
        thread-pool-size: 10
        consumer-group: event-group-test
        # 事件topic，支持追加
        topics:
          - name: event
            topic: "general_event"

      # 指标消费者
      - name: metric-consumer
        thread-pool-size: 5
        consumer-group: metric-group-test
        # 指标topic，支持追加
        topics:
          - name: metric
            topic: "general_metric"



clickhouse:
  url: http://118.25.129.41:8123/
  username: test
  password: 123456
  database: aurora
  socket-timeout: 30000
  connection-timeout: 5000

